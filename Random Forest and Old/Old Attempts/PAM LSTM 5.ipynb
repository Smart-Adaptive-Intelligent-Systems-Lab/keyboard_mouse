{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQUqRjRliqbd",
        "outputId": "de54f573-760a-4289-9c2e-8d43b5b1d4d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from sklearn.utils import resample\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from random import shuffle\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FpHmjzCFjkHS"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.0005\n",
        "weight_decay = 0.0001       # L2 regularization appled to the optimizer\n",
        "epochs = 40\n",
        "\n",
        "hidden_size = 16\n",
        "num_layers = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Opp3vbulu_sP",
        "outputId": "fed13567-7d04-4880-ed89-abe4434e6740"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            Event_Type    X    Y  PAM_Val  seq_num  delta_time\n",
            "0                 Move  518  381        4        0           0\n",
            "1                 Move  511  388        4        0     7980000\n",
            "2                 Move  509  393        4        0     7977000\n",
            "3                 Move  505  397        4        0     7978000\n",
            "4                 Move  501  399        4        0     7979000\n",
            "...                ...  ...  ...      ...      ...         ...\n",
            "4272853           Move  680  831        3       97    76169000\n",
            "4272854           Move  677  831        3       97    25399000\n",
            "4272855           Move  677  829        3       97     3894000\n",
            "4272856   Left_Pressed  677  829        3       97    75190000\n",
            "4272857  Left_Released  677  829        3       97    97661000\n",
            "\n",
            "[5117079 rows x 6 columns]\n",
            "(5117079, 6)\n",
            "(844221, 6)\n",
            "(4272858, 6)\n"
          ]
        }
      ],
      "source": [
        "user1 = pd.read_csv('user1_preprocessed_4.csv')\n",
        "user2 = pd.read_csv('user2_preprocessed_4.csv')\n",
        "\n",
        "user1.drop(columns='Time', inplace=True)\n",
        "user2.drop(columns='Time', inplace=True)\n",
        "\n",
        "user2['seq_num'] = user2['seq_num'] + user1[-1:]['seq_num'].values + 1\n",
        "\n",
        "user = pd.concat([user1, user2], axis=0)\n",
        "\n",
        "print(user)\n",
        "print(user.shape)\n",
        "print(user1.shape)\n",
        "print(user2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKMnq67zvFgG",
        "outputId": "332efca3-bced-4be0-a367-c605940057cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     X    Y  PAM_Val  seq_num  delta_time  Left_Pressed  Left_Released  Move  \\\n",
            "0  518  381        4        0           0         False          False  True   \n",
            "1  511  388        4        0     7980000         False          False  True   \n",
            "2  509  393        4        0     7977000         False          False  True   \n",
            "3  505  397        4        0     7978000         False          False  True   \n",
            "4  501  399        4        0     7979000         False          False  True   \n",
            "\n",
            "   Right_Pressed  Right_Released  Scroll  \n",
            "0          False           False   False  \n",
            "1          False           False   False  \n",
            "2          False           False   False  \n",
            "3          False           False   False  \n",
            "4          False           False   False  \n"
          ]
        }
      ],
      "source": [
        "app_one_hot_encoded = pd.get_dummies(user['Event_Type'])\n",
        "\n",
        "user.drop(columns='Event_Type', inplace=True)\n",
        "\n",
        "user = pd.concat([user, app_one_hot_encoded], axis=1)\n",
        "\n",
        "print(user.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5117079, 11)\n"
          ]
        }
      ],
      "source": [
        "print(user.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     X    Y  PAM_Val  seq_num  delta_time  Left_Pressed  Left_Released  Move  \\\n",
            "0  518  381      3.0        0           0         False          False  True   \n",
            "1  511  388      3.0        0     7980000         False          False  True   \n",
            "2  509  393      3.0        0     7977000         False          False  True   \n",
            "3  505  397      3.0        0     7978000         False          False  True   \n",
            "4  501  399      3.0        0     7979000         False          False  True   \n",
            "\n",
            "   Right_Pressed  Right_Released  Scroll  \n",
            "0          False           False   False  \n",
            "1          False           False   False  \n",
            "2          False           False   False  \n",
            "3          False           False   False  \n",
            "4          False           False   False  \n"
          ]
        }
      ],
      "source": [
        "user['PAM_Val'] = user['PAM_Val'] - 1.0\n",
        "\n",
        "print(user.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     X    Y  seq_num  delta_time  Left_Pressed  Left_Released  Move  \\\n",
            "0  518  381        0           0         False          False  True   \n",
            "1  511  388        0     7980000         False          False  True   \n",
            "2  509  393        0     7977000         False          False  True   \n",
            "3  505  397        0     7978000         False          False  True   \n",
            "4  501  399        0     7979000         False          False  True   \n",
            "\n",
            "   Right_Pressed  Right_Released  Scroll  \n",
            "0          False           False   False  \n",
            "1          False           False   False  \n",
            "2          False           False   False  \n",
            "3          False           False   False  \n",
            "4          False           False   False  \n",
            "   PAM_Val  seq_num\n",
            "0      3.0        0\n",
            "1      3.0        0\n",
            "2      3.0        0\n",
            "3      3.0        0\n",
            "4      3.0        0\n"
          ]
        }
      ],
      "source": [
        "user_X = user.drop(columns=['PAM_Val'])\n",
        "user_y = user.filter(['PAM_Val', 'seq_num'])\n",
        "\n",
        "print(user_X.head(5))\n",
        "print(user_y.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzo_w0YjgrKi",
        "outputId": "640b7525-2273-484b-f5f0-19af29188e37"
      },
      "outputs": [],
      "source": [
        "user_X = user_X.groupby(by='seq_num')\n",
        "user_y = user_y.groupby(by='seq_num')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYR2O7rAksXk",
        "outputId": "49e756ce-1d91-4b26-fda4-8b9b2062f3d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98\n",
            "100\n"
          ]
        }
      ],
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for one, two in zip(user_X, user_y):\n",
        "    X.append(pd.concat([one[1].drop(columns=['seq_num']), two[1]['PAM_Val'].shift(1)], axis=1).fillna(0).iloc[-100:].values)\n",
        "    y.append(two[1].drop(columns=['seq_num']).iloc[-5000:].values)\n",
        "\n",
        "print(len(X))\n",
        "print(len(X[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[3.]\n",
            " [3.]\n",
            " [3.]\n",
            " ...\n",
            " [3.]\n",
            " [3.]\n",
            " [3.]]\n",
            "[3.]\n"
          ]
        }
      ],
      "source": [
        "# the pam value for each timestep in a sequence is the same, so condense them into a single value per sequence\n",
        "\n",
        "print(y[0])\n",
        "\n",
        "for index in range(len(y)):\n",
        "    y[index] = y[index][-1]\n",
        "\n",
        "print(y[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OB6S0DgQi0Zk"
      },
      "outputs": [],
      "source": [
        "class RNN_Model(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
        "    super(RNN_Model, self).__init__()\n",
        "\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.output_size = output_size\n",
        "\n",
        "    self.rnn = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, batch_first=True, dropout=0.3)\n",
        "    self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
        "    #self.sm = nn.Softmax(dim=0)    # not needed if using Cross Entropy loss\n",
        "  \n",
        "  def forward(self, x):\n",
        "    batch_size = x.size(0)\n",
        "\n",
        "    h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "    c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "\n",
        "    out, hidden = self.rnn(x, (h0, c0))\n",
        "    #out = self.fc(out.contiguous().view(-1, self.hidden_size))\n",
        "    out = self.fc(out[:, -1, :])\n",
        "    #out = self.sm(out)\n",
        "\n",
        "    return out, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.  1.  2.  3.]\n",
            " [29. 47. 14.  8.]]\n",
            "tensor([0.2759, 0.1702, 0.5714, 1.0000], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "unique, counts = np.unique(y, return_counts=True)\n",
        "print(np.asarray((unique, counts)))\n",
        "\n",
        "weighted_classes = []\n",
        "minimum_count = min(counts)\n",
        "for value, count in zip(unique, counts):\n",
        "    weighted_classes.append(minimum_count / count)\n",
        "\n",
        "weighted_classes = torch.Tensor(weighted_classes).to(device)\n",
        "print(weighted_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8Qw3mz5-jUD-"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss(weight=weighted_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5BVRtsBCvJ4b"
      },
      "outputs": [],
      "source": [
        "kfold = StratifiedKFold(n_splits=3, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "iWTvlKOBvKfV",
        "outputId": "ee0a1c23-888a-482f-eac9-7f583997dda3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================== Fold 0 ========================\n",
            "epoch 1/40: train loss = 1.2931, val loss = 1.2930\n",
            "epoch 2/40: train loss = 1.2681, val loss = 1.2745\n",
            "epoch 3/40: train loss = 1.2448, val loss = 1.2537\n",
            "epoch 4/40: train loss = 1.2190, val loss = 1.2359\n",
            "epoch 5/40: train loss = 1.2016, val loss = 1.2329\n",
            "epoch 6/40: train loss = 1.1969, val loss = 1.2316\n",
            "epoch 7/40: train loss = 1.1958, val loss = 1.2304\n",
            "epoch 8/40: train loss = 1.1885, val loss = 1.2308\n",
            "epoch 9/40: train loss = 1.1933, val loss = 1.2301\n",
            "epoch 10/40: train loss = 1.1880, val loss = 1.2302\n",
            "epoch 11/40: train loss = 1.1862, val loss = 1.2307\n",
            "epoch 12/40: train loss = 1.1925, val loss = 1.2298\n",
            "epoch 13/40: train loss = 1.1907, val loss = 1.2293\n",
            "epoch 14/40: train loss = 1.1867, val loss = 1.2292\n",
            "epoch 15/40: train loss = 1.1855, val loss = 1.2294\n",
            "epoch 16/40: train loss = 1.1862, val loss = 1.2293\n",
            "epoch 17/40: train loss = 1.1892, val loss = 1.2289\n",
            "epoch 18/40: train loss = 1.1851, val loss = 1.2289\n",
            "epoch 19/40: train loss = 1.1849, val loss = 1.2290\n",
            "epoch 20/40: train loss = 1.1856, val loss = 1.2289\n",
            "epoch 21/40: train loss = 1.1894, val loss = 1.2287\n",
            "epoch 22/40: train loss = 1.1828, val loss = 1.2290\n",
            "epoch 23/40: train loss = 1.1908, val loss = 1.2285\n",
            "epoch 24/40: train loss = 1.1872, val loss = 1.2284\n",
            "epoch 25/40: train loss = 1.1868, val loss = 1.2286\n",
            "epoch 26/40: train loss = 1.1856, val loss = 1.2287\n",
            "epoch 27/40: train loss = 1.1858, val loss = 1.2289\n",
            "epoch 28/40: train loss = 1.1828, val loss = 1.2290\n",
            "epoch 29/40: train loss = 1.1889, val loss = 1.2289\n",
            "epoch 30/40: train loss = 1.1783, val loss = 1.2289\n",
            "epoch 31/40: train loss = 1.1822, val loss = 1.2288\n",
            "epoch 32/40: train loss = 1.1774, val loss = 1.2288\n",
            "epoch 33/40: train loss = 1.1794, val loss = 1.2288\n",
            "epoch 34/40: train loss = 1.1809, val loss = 1.2288\n",
            "epoch 35/40: train loss = 1.1806, val loss = 1.2287\n",
            "epoch 36/40: train loss = 1.1833, val loss = 1.2287\n",
            "epoch 37/40: train loss = 1.1808, val loss = 1.2287\n",
            "epoch 38/40: train loss = 1.1802, val loss = 1.2287\n",
            "epoch 39/40: train loss = 1.1771, val loss = 1.2287\n",
            "epoch 40/40: train loss = 1.1786, val loss = 1.2287\n",
            "Confusion Matrix:\n",
            "[[0, 19, 0, 0], [0, 32, 0, 0], [0, 9, 0, 0], [0, 5, 0, 0]]\n",
            "Accuracy:\n",
            "0.49230769230769234\n",
            "Precision:\n",
            "0.12307692307692308\n",
            "Recall:\n",
            "0.12307692307692308\n",
            "F1:\n",
            "0.12307692307692308\n",
            "\n",
            "======================== Fold 1 ========================\n",
            "epoch 1/40: train loss = 1.4234, val loss = 1.3934\n",
            "epoch 2/40: train loss = 1.3658, val loss = 1.3248\n",
            "epoch 3/40: train loss = 1.2602, val loss = 1.2300\n",
            "epoch 4/40: train loss = 1.1950, val loss = 1.2194\n",
            "epoch 5/40: train loss = 1.1954, val loss = 1.2164\n",
            "epoch 6/40: train loss = 1.2022, val loss = 1.2146\n",
            "epoch 7/40: train loss = 1.1823, val loss = 1.2146\n",
            "epoch 8/40: train loss = 1.1973, val loss = 1.2138\n",
            "epoch 9/40: train loss = 1.1932, val loss = 1.2135\n",
            "epoch 10/40: train loss = 1.1923, val loss = 1.2135\n",
            "epoch 11/40: train loss = 1.1901, val loss = 1.2135\n",
            "epoch 12/40: train loss = 1.1906, val loss = 1.2136\n",
            "epoch 13/40: train loss = 1.1883, val loss = 1.2136\n",
            "epoch 14/40: train loss = 1.1940, val loss = 1.2136\n",
            "epoch 15/40: train loss = 1.1879, val loss = 1.2141\n",
            "epoch 16/40: train loss = 1.1853, val loss = 1.2141\n",
            "epoch 17/40: train loss = 1.1883, val loss = 1.2141\n",
            "epoch 18/40: train loss = 1.1908, val loss = 1.2140\n",
            "epoch 19/40: train loss = 1.1902, val loss = 1.2140\n",
            "epoch 20/40: train loss = 1.1886, val loss = 1.2140\n",
            "epoch 21/40: train loss = 1.1872, val loss = 1.2140\n",
            "epoch 22/40: train loss = 1.1861, val loss = 1.2140\n",
            "epoch 23/40: train loss = 1.1843, val loss = 1.2140\n",
            "epoch 24/40: train loss = 1.1914, val loss = 1.2140\n",
            "epoch 25/40: train loss = 1.1898, val loss = 1.2140\n",
            "epoch 26/40: train loss = 1.1904, val loss = 1.2140\n",
            "epoch 27/40: train loss = 1.1964, val loss = 1.2140\n",
            "epoch 28/40: train loss = 1.1909, val loss = 1.2140\n",
            "epoch 29/40: train loss = 1.1964, val loss = 1.2140\n",
            "epoch 30/40: train loss = 1.1903, val loss = 1.2140\n",
            "epoch 31/40: train loss = 1.1956, val loss = 1.2140\n",
            "epoch 32/40: train loss = 1.1975, val loss = 1.2140\n",
            "epoch 33/40: train loss = 1.1870, val loss = 1.2140\n",
            "epoch 34/40: train loss = 1.1858, val loss = 1.2140\n",
            "epoch 35/40: train loss = 1.1903, val loss = 1.2140\n",
            "epoch 36/40: train loss = 1.1978, val loss = 1.2140\n",
            "epoch 37/40: train loss = 1.1843, val loss = 1.2140\n",
            "epoch 38/40: train loss = 1.1901, val loss = 1.2140\n",
            "epoch 39/40: train loss = 1.1865, val loss = 1.2140\n",
            "epoch 40/40: train loss = 1.1833, val loss = 1.2140\n",
            "Confusion Matrix:\n",
            "[[0, 20, 0, 0], [0, 31, 0, 0], [0, 9, 0, 0], [0, 5, 0, 0]]\n",
            "Accuracy:\n",
            "0.47692307692307695\n",
            "Precision:\n",
            "0.11923076923076924\n",
            "Recall:\n",
            "0.11923076923076924\n",
            "F1:\n",
            "0.11923076923076924\n",
            "\n",
            "======================== Fold 2 ========================\n",
            "epoch 1/40: train loss = 1.3685, val loss = 1.3512\n",
            "epoch 2/40: train loss = 1.3404, val loss = 1.3159\n",
            "epoch 3/40: train loss = 1.3075, val loss = 1.2579\n",
            "epoch 4/40: train loss = 1.2611, val loss = 1.1991\n",
            "epoch 5/40: train loss = 1.2325, val loss = 1.1761\n",
            "epoch 6/40: train loss = 1.2320, val loss = 1.1650\n",
            "epoch 7/40: train loss = 1.2287, val loss = 1.1603\n",
            "epoch 8/40: train loss = 1.2308, val loss = 1.1577\n",
            "epoch 9/40: train loss = 1.2255, val loss = 1.1560\n",
            "epoch 10/40: train loss = 1.2240, val loss = 1.1547\n",
            "epoch 11/40: train loss = 1.2183, val loss = 1.1540\n",
            "epoch 12/40: train loss = 1.2343, val loss = 1.1544\n",
            "epoch 13/40: train loss = 1.2254, val loss = 1.1540\n",
            "epoch 14/40: train loss = 1.2255, val loss = 1.1536\n",
            "epoch 15/40: train loss = 1.2171, val loss = 1.1531\n",
            "epoch 16/40: train loss = 1.2209, val loss = 1.1526\n",
            "epoch 17/40: train loss = 1.2238, val loss = 1.1529\n",
            "epoch 18/40: train loss = 1.2251, val loss = 1.1527\n",
            "epoch 19/40: train loss = 1.2306, val loss = 1.1531\n",
            "epoch 20/40: train loss = 1.2221, val loss = 1.1527\n",
            "epoch 21/40: train loss = 1.2280, val loss = 1.1525\n",
            "epoch 22/40: train loss = 1.2286, val loss = 1.1526\n",
            "epoch 23/40: train loss = 1.2260, val loss = 1.1524\n",
            "epoch 24/40: train loss = 1.2208, val loss = 1.1526\n",
            "epoch 25/40: train loss = 1.2231, val loss = 1.1525\n",
            "epoch 26/40: train loss = 1.2303, val loss = 1.1535\n",
            "epoch 27/40: train loss = 1.2209, val loss = 1.1532\n",
            "epoch 28/40: train loss = 1.2274, val loss = 1.1529\n",
            "epoch 29/40: train loss = 1.2335, val loss = 1.1535\n",
            "epoch 30/40: train loss = 1.2181, val loss = 1.1535\n",
            "epoch 31/40: train loss = 1.2221, val loss = 1.1535\n",
            "epoch 32/40: train loss = 1.2170, val loss = 1.1534\n",
            "epoch 33/40: train loss = 1.2199, val loss = 1.1534\n",
            "epoch 34/40: train loss = 1.2203, val loss = 1.1534\n",
            "epoch 35/40: train loss = 1.2191, val loss = 1.1534\n",
            "epoch 36/40: train loss = 1.2209, val loss = 1.1534\n",
            "epoch 37/40: train loss = 1.2276, val loss = 1.1534\n",
            "epoch 38/40: train loss = 1.2124, val loss = 1.1534\n",
            "epoch 39/40: train loss = 1.2160, val loss = 1.1534\n",
            "epoch 40/40: train loss = 1.2154, val loss = 1.1534\n",
            "Confusion Matrix:\n",
            "[[0, 19, 0, 0], [0, 31, 0, 0], [0, 10, 0, 0], [0, 6, 0, 0]]\n",
            "Accuracy:\n",
            "0.4696969696969697\n",
            "Precision:\n",
            "0.11742424242424243\n",
            "Recall:\n",
            "0.11742424242424243\n",
            "F1:\n",
            "0.11742424242424243\n",
            "\n"
          ]
        }
      ],
      "source": [
        "comb_accuracy = []\n",
        "comb_precision = []\n",
        "comb_recall = []\n",
        "comb_f1 = []\n",
        "comb_accuracy_train = []\n",
        "comb_precision_train = []\n",
        "comb_recall_train = []\n",
        "comb_f1_train = []\n",
        "for i, (train_index, test_index) in enumerate(kfold.split(X, y)):\n",
        "    print(f\"======================== Fold {i} ========================\")\n",
        "\n",
        "    X_train = np.array(X)[train_index].tolist()\n",
        "    y_train = np.array(y)[train_index].tolist()\n",
        "\n",
        "    X_test = np.array(X)[test_index].tolist()\n",
        "    y_test = np.array(y)[test_index].tolist()\n",
        "\n",
        "    class_weights = []\n",
        "\n",
        "    # ===== train ===== #\n",
        "    model = RNN_Model(len(X_train[0][0]), hidden_size, 4, num_layers)\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      model.train()\n",
        "      train_loss = 0.0\n",
        "      for sample, label in zip(X_train, y_train):\n",
        "        sample = torch.Tensor([sample]).to(device)\n",
        "        label = torch.Tensor(label).type(torch.cuda.LongTensor).to(device)\n",
        "\n",
        "        outputs, hidden = model(sample)\n",
        "\n",
        "        loss = loss_fn(outputs, label)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss\n",
        "\n",
        "      train_loss /= len(X_train)\n",
        "\n",
        "      model.eval()\n",
        "      val_loss = 0.0\n",
        "      with torch.no_grad():\n",
        "        for sample, label in zip(X_test, y_test):\n",
        "          sample = torch.Tensor([sample]).to(device)\n",
        "          label = torch.Tensor(label).type(torch.cuda.LongTensor).to(device)\n",
        "\n",
        "          outputs, hidden = model(sample)\n",
        "          loss = loss_fn(outputs, label)\n",
        "          val_loss += loss\n",
        "      \n",
        "      val_loss /= len(X_test)\n",
        "      scheduler.step(val_loss)\n",
        "\n",
        "      print(f'epoch {epoch+1}/{epochs}: train loss = {train_loss:.4f}, val loss = {val_loss:.4f}')\n",
        "\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # ===== metrics on training splits ===== #\n",
        "    conf_matrix_train = []\n",
        "    accuracy_train = []\n",
        "    precision_train = []\n",
        "    recall_train = []\n",
        "    f1_train = []\n",
        "    with torch.no_grad():\n",
        "      for sample, label in zip(X_train, y_train):\n",
        "        sample = torch.Tensor([sample]).to(device)\n",
        "        label = torch.Tensor(label).type(torch.cuda.LongTensor).to(device)\n",
        "        label = label.to('cpu')\n",
        "\n",
        "        outputs, hidden = model(sample)\n",
        "        _, y_pred_train = torch.max(outputs, 1)  # returns value, index\n",
        "\n",
        "        y_pred_train_cpu = y_pred_train.to('cpu')\n",
        "\n",
        "        conf_matrix_train.append(confusion_matrix(label, y_pred_train_cpu, labels=[0,1,2,3]))\n",
        "        accuracy_train.append(accuracy_score(label, y_pred_train_cpu))\n",
        "        precision_train.append(precision_score(label, y_pred_train_cpu, labels=[0,1,2,3], average='macro'))\n",
        "        recall_train.append(recall_score(label, y_pred_train_cpu, labels=[0,1,2,3], average='macro'))\n",
        "        f1_train.append(f1_score(label, y_pred_train_cpu, labels=[0,1,2,3], average='macro'))\n",
        "    \n",
        "    conf_matrix_train = np.array(conf_matrix_train).sum(axis=0).tolist()\n",
        "    accuracy_train = np.array(accuracy_train).mean(axis=0).tolist()\n",
        "    precision_train = np.array(precision_train).mean(axis=0).tolist()\n",
        "    recall_train = np.array(recall_train).mean(axis=0).tolist()\n",
        "    f1_train = np.array(f1_train).mean(axis=0).tolist()\n",
        "\n",
        "    # ===== metrics on test split(s) ===== #\n",
        "    conf_matrix = []\n",
        "    accuracy = []\n",
        "    precision = []\n",
        "    recall = []\n",
        "    f1 = []\n",
        "    with torch.no_grad():\n",
        "      for sample, label in zip(X_test, y_test):\n",
        "        sample = torch.Tensor([sample]).to(device)\n",
        "        label = torch.Tensor(label).type(torch.cuda.LongTensor).to(device)\n",
        "        label = label.to('cpu')\n",
        "\n",
        "        outputs, hidden = model(sample)\n",
        "        _, y_pred = torch.max(outputs, 1)  # returns value, index\n",
        "\n",
        "        y_pred_cpu = y_pred.to('cpu')\n",
        "\n",
        "        conf_matrix.append(confusion_matrix(label, y_pred_cpu, labels=[0,1,2,3]))\n",
        "        accuracy.append(accuracy_score(label, y_pred_cpu))\n",
        "        precision.append(precision_score(label, y_pred_cpu, labels=[0,1,2,3], average='macro'))\n",
        "        recall.append(recall_score(label, y_pred_cpu, labels=[0,1,2,3], average='macro'))\n",
        "        f1.append(f1_score(label, y_pred_cpu, labels=[0,1,2,3], average='macro'))\n",
        "    \n",
        "    conf_matrix = np.array(conf_matrix).sum(axis=0).tolist()\n",
        "    accuracy = np.array(accuracy).mean(axis=0).tolist()\n",
        "    precision = np.array(precision).mean(axis=0).tolist()\n",
        "    recall = np.array(recall).mean(axis=0).tolist()\n",
        "    f1 = np.array(f1).mean(axis=0).tolist()\n",
        "\n",
        "\n",
        "\n",
        "    comb_accuracy_train.append(accuracy_train)\n",
        "    comb_precision_train.append(precision_train)\n",
        "    comb_recall_train.append(recall_train)\n",
        "    comb_f1_train.append(f1_train)\n",
        "\n",
        "    comb_accuracy.append(accuracy)\n",
        "    comb_precision.append(precision)\n",
        "    comb_recall.append(recall)\n",
        "    comb_f1.append(f1)\n",
        "\n",
        "    print('Confusion Matrix:')\n",
        "    print(conf_matrix_train)\n",
        "    print('Accuracy:')\n",
        "    print(accuracy_train)\n",
        "    print('Precision:')\n",
        "    print(precision_train)\n",
        "    print('Recall:')\n",
        "    print(recall_train)\n",
        "    print('F1:')\n",
        "    print(f1_train)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EPk3L9fYbRQg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy:\n",
            "0.47964257964257967\n",
            "0.47979797979797983\n",
            "Average Precision:\n",
            "0.11991064491064492\n",
            "0.11994949494949496\n",
            "Average Recall:\n",
            "0.11991064491064492\n",
            "0.11994949494949496\n",
            "Average F1:\n",
            "0.11991064491064492\n",
            "0.11994949494949496\n"
          ]
        }
      ],
      "source": [
        "comb_accuracy_train = np.array(comb_accuracy_train)\n",
        "comb_precision_train = np.array(comb_precision_train)\n",
        "comb_recall_train = np.array(comb_recall_train)\n",
        "comb_f1_train = np.array(comb_f1_train)\n",
        "\n",
        "comb_accuracy = np.array(comb_accuracy)\n",
        "comb_precision = np.array(comb_precision)\n",
        "comb_recall = np.array(comb_recall)\n",
        "comb_f1 = np.array(comb_f1)\n",
        "\n",
        "print('Average Accuracy:')\n",
        "print(comb_accuracy_train.mean(axis=0))\n",
        "print(comb_accuracy.mean(axis=0))\n",
        "print('Average Precision:')\n",
        "print(comb_precision_train.mean(axis=0))\n",
        "print(comb_precision.mean(axis=0))\n",
        "print('Average Recall:')\n",
        "print(comb_recall_train.mean(axis=0))\n",
        "print(comb_recall.mean(axis=0))\n",
        "print('Average F1:')\n",
        "print(comb_f1_train.mean(axis=0))\n",
        "print(comb_f1.mean(axis=0))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "772f66837d71377a9e91bdceabcb0d3cb18014278592638634865ba084916021"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
