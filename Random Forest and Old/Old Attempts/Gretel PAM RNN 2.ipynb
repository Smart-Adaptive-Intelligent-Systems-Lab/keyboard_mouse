{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQUqRjRliqbd",
        "outputId": "de54f573-760a-4289-9c2e-8d43b5b1d4d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from random import shuffle\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FpHmjzCFjkHS"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "epochs = 40\n",
        "\n",
        "hidden_size = 128\n",
        "num_layers = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Opp3vbulu_sP",
        "outputId": "fed13567-7d04-4880-ed89-abe4434e6740"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                     Inactivity Duration(s)  Speed(ms)  Prev_PAM_Val  PAM_Val  \\\n",
            "Time                                                                            \n",
            "2021-09-10 13:30:00             5157.560547  12.659453           0.0        3   \n",
            "2021-09-10 14:00:00             4467.798340  12.544724           3.0        1   \n",
            "2021-09-10 14:30:00             5052.699219  11.190955           1.0        3   \n",
            "2021-09-10 15:00:00             4072.605957  12.184985           3.0        3   \n",
            "2021-09-10 15:30:00             3371.592285  11.939060           3.0        3   \n",
            "\n",
            "                     example_id  \n",
            "Time                             \n",
            "2021-09-10 13:30:00           0  \n",
            "2021-09-10 14:00:00           0  \n",
            "2021-09-10 14:30:00           0  \n",
            "2021-09-10 15:00:00           0  \n",
            "2021-09-10 15:30:00           0  \n",
            "(9600, 5)\n"
          ]
        }
      ],
      "source": [
        "user = pd.read_csv('postprocessed_id_200-100.csv')\n",
        "\n",
        "user = user.set_index(pd.DatetimeIndex(user['Time']))\n",
        "\n",
        "user = user.filter(items=['Inactivity Duration(s)', 'Speed(ms)', 'Prev_PAM_Val', 'PAM_Val', 'example_id'])\n",
        "\n",
        "\n",
        "print(user.head(5))\n",
        "print(user.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(9600, 5)\n",
            "1     737\n",
            "2    6971\n",
            "3    1881\n",
            "4      11\n",
            "Name: PAM_Val, dtype: int64\n",
            "1    0.076771\n",
            "2    0.726146\n",
            "3    0.195937\n",
            "4    0.001146\n",
            "Name: PAM_Val, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(user.shape)\n",
        "print(user.PAM_Val.value_counts().sort_index())\n",
        "print(user.PAM_Val.value_counts(normalize=True).sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                     Inactivity Duration(s)  Speed(ms)  Prev_PAM_Val  PAM_Val  \\\n",
            "Time                                                                            \n",
            "2021-09-10 13:30:00             5157.560547  12.659453          -1.0      2.0   \n",
            "2021-09-10 14:00:00             4467.798340  12.544724           2.0      0.0   \n",
            "2021-09-10 14:30:00             5052.699219  11.190955           0.0      2.0   \n",
            "2021-09-10 15:00:00             4072.605957  12.184985           2.0      2.0   \n",
            "2021-09-10 15:30:00             3371.592285  11.939060           2.0      2.0   \n",
            "\n",
            "                     example_id  \n",
            "Time                             \n",
            "2021-09-10 13:30:00           0  \n",
            "2021-09-10 14:00:00           0  \n",
            "2021-09-10 14:30:00           0  \n",
            "2021-09-10 15:00:00           0  \n",
            "2021-09-10 15:30:00           0  \n"
          ]
        }
      ],
      "source": [
        "user['PAM_Val'] = user['PAM_Val'] - 1.0\n",
        "\n",
        "user['Prev_PAM_Val'] = user['Prev_PAM_Val'] - 1.0\n",
        "\n",
        "print(user.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzo_w0YjgrKi",
        "outputId": "640b7525-2273-484b-f5f0-19af29188e37"
      },
      "outputs": [],
      "source": [
        "user_train_group = user.groupby(by='example_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1200\n",
            "                     Inactivity Duration(s)  Speed(ms)  Prev_PAM_Val\n",
            "Time                                                                \n",
            "2021-09-10 13:30:00             5157.560547  12.659453          -1.0\n",
            "2021-09-10 14:00:00             4467.798340  12.544724           2.0\n",
            "2021-09-10 14:30:00             5052.699219  11.190955           0.0\n",
            "2021-09-10 15:00:00             4072.605957  12.184985           2.0\n",
            "2021-09-10 15:30:00             3371.592285  11.939060           2.0\n",
            "2021-09-10 16:00:00             1631.225342   8.710327           2.0\n",
            "2021-09-10 16:30:00             1460.209229   5.946492           1.0\n",
            "2021-09-10 17:00:00              648.464111   5.012145           1.0\n",
            "                     PAM_Val\n",
            "Time                        \n",
            "2021-09-10 13:30:00      2.0\n",
            "2021-09-10 14:00:00      0.0\n",
            "2021-09-10 14:30:00      2.0\n",
            "2021-09-10 15:00:00      2.0\n",
            "2021-09-10 15:30:00      2.0\n",
            "2021-09-10 16:00:00      1.0\n",
            "2021-09-10 16:30:00      1.0\n",
            "2021-09-10 17:00:00      1.0\n"
          ]
        }
      ],
      "source": [
        "user_train_X = []\n",
        "user_train_y = []\n",
        "for group, df in user_train_group:\n",
        "    user_train_X.append(df.drop(columns=['PAM_Val', 'example_id']))\n",
        "    user_train_y.append(df.filter(['PAM_Val']))\n",
        "\n",
        "\n",
        "print(len(user_train_X))\n",
        "print(user_train_X[0])\n",
        "print(user_train_y[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = user_train_X\n",
        "y = user_train_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OB6S0DgQi0Zk"
      },
      "outputs": [],
      "source": [
        "class RNN_Model(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
        "    super(RNN_Model, self).__init__()\n",
        "\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.output_size = output_size\n",
        "\n",
        "    self.rnn = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, batch_first=True)\n",
        "    self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
        "    #self.sm = nn.Softmax(dim=0)    # not needed if using Cross Entropy loss\n",
        "  \n",
        "  def forward(self, x):\n",
        "    batch_size = x.size(0)\n",
        "\n",
        "    h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "    c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "\n",
        "    out, hidden = self.rnn(x, (h0, c0))\n",
        "    out = self.fc(out.contiguous().view(-1, self.hidden_size))\n",
        "\n",
        "    return out, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8Qw3mz5-jUD-"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5BVRtsBCvJ4b"
      },
      "outputs": [],
      "source": [
        "kfold = KFold(n_splits=5, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "iWTvlKOBvKfV",
        "outputId": "ee0a1c23-888a-482f-eac9-7f583997dda3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================== Fold 0 ========================\n",
            "epoch 1/40: loss = 0.7341\n",
            "epoch 2/40: loss = 0.7040\n",
            "epoch 3/40: loss = 0.7004\n",
            "epoch 4/40: loss = 0.6989\n",
            "epoch 5/40: loss = 0.6981\n",
            "epoch 6/40: loss = 0.6945\n",
            "epoch 7/40: loss = 0.6921\n",
            "epoch 8/40: loss = 0.6919\n",
            "epoch 9/40: loss = 0.6919\n",
            "epoch 10/40: loss = 0.6918\n",
            "epoch 11/40: loss = 0.6907\n",
            "epoch 12/40: loss = 0.6907\n",
            "epoch 13/40: loss = 0.6907\n",
            "epoch 14/40: loss = 0.6906\n",
            "epoch 15/40: loss = 0.6906\n",
            "epoch 16/40: loss = 0.6905\n",
            "epoch 17/40: loss = 0.6905\n",
            "epoch 18/40: loss = 0.6905\n",
            "epoch 19/40: loss = 0.6905\n",
            "epoch 20/40: loss = 0.6905\n",
            "epoch 21/40: loss = 0.6905\n",
            "epoch 22/40: loss = 0.6905\n",
            "epoch 23/40: loss = 0.6905\n",
            "epoch 24/40: loss = 0.6905\n",
            "epoch 25/40: loss = 0.6905\n",
            "epoch 26/40: loss = 0.6905\n",
            "epoch 27/40: loss = 0.6905\n",
            "epoch 28/40: loss = 0.6905\n",
            "epoch 29/40: loss = 0.6905\n",
            "epoch 30/40: loss = 0.6905\n",
            "epoch 31/40: loss = 0.6905\n",
            "epoch 32/40: loss = 0.6905\n",
            "epoch 33/40: loss = 0.6905\n",
            "epoch 34/40: loss = 0.6905\n",
            "epoch 35/40: loss = 0.6905\n",
            "epoch 36/40: loss = 0.6905\n",
            "epoch 37/40: loss = 0.6905\n",
            "epoch 38/40: loss = 0.6905\n",
            "epoch 39/40: loss = 0.6905\n",
            "epoch 40/40: loss = 0.6905\n",
            "Confusion Matrix:\n",
            "[[   0  591    0    0]\n",
            " [   0 5570    0    0]\n",
            " [   0 1511    0    0]\n",
            " [   0    8    0    0]]\n",
            "Accuracy:\n",
            "0.7252604166666666\n",
            "Precision:\n",
            "0.18131510416666666\n",
            "Recall:\n",
            "0.2453125\n",
            "F1:\n",
            "0.19953726828726828\n",
            "\n",
            "======================== Fold 1 ========================\n",
            "epoch 1/40: loss = 0.7304\n",
            "epoch 2/40: loss = 0.7005\n",
            "epoch 3/40: loss = 0.6962\n",
            "epoch 4/40: loss = 0.6943\n",
            "epoch 5/40: loss = 0.6932\n",
            "epoch 6/40: loss = 0.6887\n",
            "epoch 7/40: loss = 0.6861\n",
            "epoch 8/40: loss = 0.6860\n",
            "epoch 9/40: loss = 0.6859\n",
            "epoch 10/40: loss = 0.6859\n",
            "epoch 11/40: loss = 0.6848\n",
            "epoch 12/40: loss = 0.6848\n",
            "epoch 13/40: loss = 0.6848\n",
            "epoch 14/40: loss = 0.6848\n",
            "epoch 15/40: loss = 0.6848\n",
            "epoch 16/40: loss = 0.6847\n",
            "epoch 17/40: loss = 0.6847\n",
            "epoch 18/40: loss = 0.6847\n",
            "epoch 19/40: loss = 0.6847\n",
            "epoch 20/40: loss = 0.6847\n",
            "epoch 21/40: loss = 0.6846\n",
            "epoch 22/40: loss = 0.6846\n",
            "epoch 23/40: loss = 0.6846\n",
            "epoch 24/40: loss = 0.6846\n",
            "epoch 25/40: loss = 0.6846\n",
            "epoch 26/40: loss = 0.6846\n",
            "epoch 27/40: loss = 0.6846\n",
            "epoch 28/40: loss = 0.6846\n",
            "epoch 29/40: loss = 0.6846\n",
            "epoch 30/40: loss = 0.6846\n",
            "epoch 31/40: loss = 0.6846\n",
            "epoch 32/40: loss = 0.6846\n",
            "epoch 33/40: loss = 0.6846\n",
            "epoch 34/40: loss = 0.6846\n",
            "epoch 35/40: loss = 0.6846\n",
            "epoch 36/40: loss = 0.6846\n",
            "epoch 37/40: loss = 0.6846\n",
            "epoch 38/40: loss = 0.6846\n",
            "epoch 39/40: loss = 0.6846\n",
            "epoch 40/40: loss = 0.6846\n",
            "Confusion Matrix:\n",
            "[[   0  579    0    0]\n",
            " [   0 5582    0    0]\n",
            " [   0 1512    0    0]\n",
            " [   0    7    0    0]]\n",
            "Accuracy:\n",
            "0.7268229166666667\n",
            "Precision:\n",
            "0.18170572916666666\n",
            "Recall:\n",
            "0.24583333333333332\n",
            "F1:\n",
            "0.19991932257557257\n",
            "\n",
            "======================== Fold 2 ========================\n",
            "epoch 1/40: loss = 0.7294\n",
            "epoch 2/40: loss = 0.6980\n",
            "epoch 3/40: loss = 0.6935\n",
            "epoch 4/40: loss = 0.6919\n",
            "epoch 5/40: loss = 0.6910\n",
            "epoch 6/40: loss = 0.6867\n",
            "epoch 7/40: loss = 0.6834\n",
            "epoch 8/40: loss = 0.6832\n",
            "epoch 9/40: loss = 0.6832\n",
            "epoch 10/40: loss = 0.6832\n",
            "epoch 11/40: loss = 0.6820\n",
            "epoch 12/40: loss = 0.6819\n",
            "epoch 13/40: loss = 0.6819\n",
            "epoch 14/40: loss = 0.6819\n",
            "epoch 15/40: loss = 0.6819\n",
            "epoch 16/40: loss = 0.6817\n",
            "epoch 17/40: loss = 0.6817\n",
            "epoch 18/40: loss = 0.6817\n",
            "epoch 19/40: loss = 0.6817\n",
            "epoch 20/40: loss = 0.6817\n",
            "epoch 21/40: loss = 0.6817\n",
            "epoch 22/40: loss = 0.6817\n",
            "epoch 23/40: loss = 0.6817\n",
            "epoch 24/40: loss = 0.6817\n",
            "epoch 25/40: loss = 0.6817\n",
            "epoch 26/40: loss = 0.6817\n",
            "epoch 27/40: loss = 0.6817\n",
            "epoch 28/40: loss = 0.6817\n",
            "epoch 29/40: loss = 0.6817\n",
            "epoch 30/40: loss = 0.6817\n",
            "epoch 31/40: loss = 0.6817\n",
            "epoch 32/40: loss = 0.6817\n",
            "epoch 33/40: loss = 0.6817\n",
            "epoch 34/40: loss = 0.6817\n",
            "epoch 35/40: loss = 0.6817\n",
            "epoch 36/40: loss = 0.6817\n",
            "epoch 37/40: loss = 0.6817\n",
            "epoch 38/40: loss = 0.6817\n",
            "epoch 39/40: loss = 0.6817\n",
            "epoch 40/40: loss = 0.6817\n",
            "Confusion Matrix:\n",
            "[[   0  565    0    0]\n",
            " [   0 5617    0    0]\n",
            " [   0 1487    0    0]\n",
            " [   0   11    0    0]]\n",
            "Accuracy:\n",
            "0.7313802083333333\n",
            "Precision:\n",
            "0.18284505208333332\n",
            "Recall:\n",
            "0.24583333333333332\n",
            "F1:\n",
            "0.20113482004107003\n",
            "\n",
            "======================== Fold 3 ========================\n",
            "epoch 1/40: loss = 0.7404\n",
            "epoch 2/40: loss = 0.7126\n",
            "epoch 3/40: loss = 0.7088\n",
            "epoch 4/40: loss = 0.7073\n",
            "epoch 5/40: loss = 0.7064\n",
            "epoch 6/40: loss = 0.7004\n",
            "epoch 7/40: loss = 0.6994\n",
            "epoch 8/40: loss = 0.6994\n",
            "epoch 9/40: loss = 0.6994\n",
            "epoch 10/40: loss = 0.6994\n",
            "epoch 11/40: loss = 0.6984\n",
            "epoch 12/40: loss = 0.6983\n",
            "epoch 13/40: loss = 0.6983\n",
            "epoch 14/40: loss = 0.6983\n",
            "epoch 15/40: loss = 0.6983\n",
            "epoch 16/40: loss = 0.6981\n",
            "epoch 17/40: loss = 0.6981\n",
            "epoch 18/40: loss = 0.6981\n",
            "epoch 19/40: loss = 0.6981\n",
            "epoch 20/40: loss = 0.6981\n",
            "epoch 21/40: loss = 0.6981\n",
            "epoch 22/40: loss = 0.6981\n",
            "epoch 23/40: loss = 0.6981\n",
            "epoch 24/40: loss = 0.6981\n",
            "epoch 25/40: loss = 0.6981\n",
            "epoch 26/40: loss = 0.6981\n",
            "epoch 27/40: loss = 0.6981\n",
            "epoch 28/40: loss = 0.6981\n",
            "epoch 29/40: loss = 0.6981\n",
            "epoch 30/40: loss = 0.6981\n",
            "epoch 31/40: loss = 0.6981\n",
            "epoch 32/40: loss = 0.6981\n",
            "epoch 33/40: loss = 0.6981\n",
            "epoch 34/40: loss = 0.6981\n",
            "epoch 35/40: loss = 0.6981\n",
            "epoch 36/40: loss = 0.6981\n",
            "epoch 37/40: loss = 0.6981\n",
            "epoch 38/40: loss = 0.6981\n",
            "epoch 39/40: loss = 0.6981\n",
            "epoch 40/40: loss = 0.6981\n",
            "Confusion Matrix:\n",
            "[[   0  614    0    0]\n",
            " [   0 5553    0    0]\n",
            " [   0 1505    0    0]\n",
            " [   0    8    0    0]]\n",
            "Accuracy:\n",
            "0.723046875\n",
            "Precision:\n",
            "0.18076171875\n",
            "Recall:\n",
            "0.24583333333333332\n",
            "F1:\n",
            "0.19940110815110815\n",
            "\n",
            "======================== Fold 4 ========================\n",
            "epoch 1/40: loss = 0.7357\n",
            "epoch 2/40: loss = 0.7069\n",
            "epoch 3/40: loss = 0.7035\n",
            "epoch 4/40: loss = 0.7020\n",
            "epoch 5/40: loss = 0.7011\n",
            "epoch 6/40: loss = 0.6969\n",
            "epoch 7/40: loss = 0.6944\n",
            "epoch 8/40: loss = 0.6943\n",
            "epoch 9/40: loss = 0.6943\n",
            "epoch 10/40: loss = 0.6943\n",
            "epoch 11/40: loss = 0.6933\n",
            "epoch 12/40: loss = 0.6932\n",
            "epoch 13/40: loss = 0.6931\n",
            "epoch 14/40: loss = 0.6931\n",
            "epoch 15/40: loss = 0.6931\n",
            "epoch 16/40: loss = 0.6929\n",
            "epoch 17/40: loss = 0.6929\n",
            "epoch 18/40: loss = 0.6929\n",
            "epoch 19/40: loss = 0.6929\n",
            "epoch 20/40: loss = 0.6929\n",
            "epoch 21/40: loss = 0.6929\n",
            "epoch 22/40: loss = 0.6929\n",
            "epoch 23/40: loss = 0.6929\n",
            "epoch 24/40: loss = 0.6929\n",
            "epoch 25/40: loss = 0.6929\n",
            "epoch 26/40: loss = 0.6929\n",
            "epoch 27/40: loss = 0.6929\n",
            "epoch 28/40: loss = 0.6929\n",
            "epoch 29/40: loss = 0.6929\n",
            "epoch 30/40: loss = 0.6929\n",
            "epoch 31/40: loss = 0.6929\n",
            "epoch 32/40: loss = 0.6929\n",
            "epoch 33/40: loss = 0.6929\n",
            "epoch 34/40: loss = 0.6929\n",
            "epoch 35/40: loss = 0.6929\n",
            "epoch 36/40: loss = 0.6929\n",
            "epoch 37/40: loss = 0.6929\n",
            "epoch 38/40: loss = 0.6929\n",
            "epoch 39/40: loss = 0.6929\n",
            "epoch 40/40: loss = 0.6929\n",
            "Confusion Matrix:\n",
            "[[   0  599    0    0]\n",
            " [   0 5562    0    0]\n",
            " [   0 1509    0    0]\n",
            " [   0   10    0    0]]\n",
            "Accuracy:\n",
            "0.72421875\n",
            "Precision:\n",
            "0.1810546875\n",
            "Recall:\n",
            "0.2453125\n",
            "F1:\n",
            "0.1994810629185629\n",
            "\n"
          ]
        }
      ],
      "source": [
        "comb_accuracy = []\n",
        "comb_precision = []\n",
        "comb_recall = []\n",
        "comb_f1 = []\n",
        "comb_accuracy_train = []\n",
        "comb_precision_train = []\n",
        "comb_recall_train = []\n",
        "comb_f1_train = []\n",
        "for i, (train_index, test_index) in enumerate(kfold.split(X)):\n",
        "    print(f\"======================== Fold {i} ========================\")\n",
        "\n",
        "    X_train = np.array(X)[train_index].tolist()\n",
        "    y_train = np.array(y)[train_index].tolist()\n",
        "\n",
        "    model = RNN_Model(len(X_train[0][0]), hidden_size, 4, num_layers)\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      losses_in_epoch = []\n",
        "      for sample, label in zip(X_train, y_train):\n",
        "\n",
        "        sample = torch.Tensor([sample]).to(device)\n",
        "        label = torch.Tensor(label).flatten().type(torch.cuda.LongTensor).to(device)\n",
        "\n",
        "        outputs, hidden = model(sample)\n",
        "\n",
        "        loss = loss_fn(outputs, label)\n",
        "        losses_in_epoch.append(loss)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "      average_loss = sum(losses_in_epoch) / len(losses_in_epoch)\n",
        "      print(f'epoch {epoch+1}/{epochs}: loss = {average_loss:.4f}')\n",
        "      scheduler.step()\n",
        "\n",
        "    conf_matrix_train = []\n",
        "    accuracy_train = []\n",
        "    precision_train = []\n",
        "    recall_train = []\n",
        "    f1_train = []\n",
        "    with torch.no_grad():\n",
        "      for sample, label in zip(X_train, y_train):\n",
        "        sample = torch.Tensor([sample]).to(device)\n",
        "        label = torch.Tensor(label).flatten().type(torch.cuda.LongTensor).to(device)\n",
        "        label = label.to('cpu')\n",
        "\n",
        "        outputs, hidden = model(sample)\n",
        "        _, y_pred_train = torch.max(outputs, 1)  # returns value, index\n",
        "\n",
        "        y_pred_train_cpu = y_pred_train.to('cpu')\n",
        "\n",
        "        conf_matrix_train.append(confusion_matrix(label, y_pred_train_cpu, labels=[0,1,2,3]))\n",
        "        accuracy_train.append(accuracy_score(label, y_pred_train_cpu))\n",
        "        precision_train.append(precision_score(label, y_pred_train_cpu, labels=[0,1,2,3], average='macro'))\n",
        "        recall_train.append(recall_score(label, y_pred_train_cpu, labels=[0,1,2,3], average='macro'))\n",
        "        f1_train.append(f1_score(label, y_pred_train_cpu, labels=[0,1,2,3], average='macro'))\n",
        "    \n",
        "    conf_matrix_train = np.array(conf_matrix_train).sum(axis=0).tolist()\n",
        "    accuracy_train = np.array(accuracy_train).mean(axis=0).tolist()\n",
        "    precision_train = np.array(precision_train).mean(axis=0).tolist()\n",
        "    recall_train = np.array(recall_train).mean(axis=0).tolist()\n",
        "    f1_train = np.array(f1_train).mean(axis=0).tolist()\n",
        "\n",
        "    X_test = np.array(X)[test_index].tolist()\n",
        "    y_test = np.array(y)[test_index].tolist()\n",
        "    conf_matrix = []\n",
        "    accuracy = []\n",
        "    precision = []\n",
        "    recall = []\n",
        "    f1 = []\n",
        "    with torch.no_grad():\n",
        "      for sample, label in zip(X_test, y_test):\n",
        "        sample = torch.Tensor([sample]).to(device)\n",
        "        label = torch.Tensor(label).flatten().type(torch.cuda.LongTensor).to(device)\n",
        "        label = label.to('cpu')\n",
        "\n",
        "        outputs, hidden = model(sample)\n",
        "        _, y_pred = torch.max(outputs, 1)  # returns value, index\n",
        "\n",
        "        y_pred_cpu = y_pred.to('cpu')\n",
        "\n",
        "        conf_matrix.append(confusion_matrix(label, y_pred_cpu, labels=[0,1,2,3]))\n",
        "        accuracy.append(accuracy_score(label, y_pred_cpu))\n",
        "        precision.append(precision_score(label, y_pred_cpu, labels=[0,1,2,3], average='macro'))\n",
        "        recall.append(recall_score(label, y_pred_cpu, labels=[0,1,2,3], average='macro'))\n",
        "        f1.append(f1_score(label, y_pred_cpu, labels=[0,1,2,3], average='macro'))\n",
        "    \n",
        "    conf_matrix = np.array(conf_matrix).sum(axis=0).tolist()\n",
        "    accuracy = np.array(accuracy).mean(axis=0).tolist()\n",
        "    precision = np.array(precision).mean(axis=0).tolist()\n",
        "    recall = np.array(recall).mean(axis=0).tolist()\n",
        "    f1 = np.array(f1).mean(axis=0).tolist()\n",
        "\n",
        "\n",
        "\n",
        "    comb_accuracy_train.append(accuracy_train)\n",
        "    comb_precision_train.append(precision_train)\n",
        "    comb_recall_train.append(recall_train)\n",
        "    comb_f1_train.append(f1_train)\n",
        "\n",
        "    comb_accuracy.append(accuracy)\n",
        "    comb_precision.append(precision)\n",
        "    comb_recall.append(recall)\n",
        "    comb_f1.append(f1)\n",
        "\n",
        "    print('Confusion Matrix:')\n",
        "    print(np.array(conf_matrix_train))\n",
        "    print('Accuracy:')\n",
        "    print(accuracy_train)\n",
        "    print('Precision:')\n",
        "    print(precision_train)\n",
        "    print('Recall:')\n",
        "    print(recall_train)\n",
        "    print('F1:')\n",
        "    print(f1_train)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "EPk3L9fYbRQg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy:\n",
            "0.7261458333333334\n",
            "0.7261458333333333\n",
            "Average Precision:\n",
            "0.18153645833333334\n",
            "0.18153645833333332\n",
            "Average Recall:\n",
            "0.24562499999999998\n",
            "0.24562499999999998\n",
            "Average F1:\n",
            "0.1998947163947164\n",
            "0.1998947163947164\n"
          ]
        }
      ],
      "source": [
        "comb_accuracy_train = np.array(comb_accuracy_train)\n",
        "comb_precision_train = np.array(comb_precision_train)\n",
        "comb_recall_train = np.array(comb_recall_train)\n",
        "comb_f1_train = np.array(comb_f1_train)\n",
        "\n",
        "comb_accuracy = np.array(comb_accuracy)\n",
        "comb_precision = np.array(comb_precision)\n",
        "comb_recall = np.array(comb_recall)\n",
        "comb_f1 = np.array(comb_f1)\n",
        "\n",
        "print('Average Accuracy:')\n",
        "print(comb_accuracy_train.mean(axis=0))\n",
        "print(comb_accuracy.mean(axis=0))\n",
        "print('Average Precision:')\n",
        "print(comb_precision_train.mean(axis=0))\n",
        "print(comb_precision.mean(axis=0))\n",
        "print('Average Recall:')\n",
        "print(comb_recall_train.mean(axis=0))\n",
        "print(comb_recall.mean(axis=0))\n",
        "print('Average F1:')\n",
        "print(comb_f1_train.mean(axis=0))\n",
        "print(comb_f1.mean(axis=0))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "772f66837d71377a9e91bdceabcb0d3cb18014278592638634865ba084916021"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
